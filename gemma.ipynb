{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
<<<<<<< HEAD
      "Requirement already satisfied: tensorflow in /home/ubuntu/.pyenv/versions/3.10.5/envs/jupyter3.10.5/lib/python3.10/site-packages (2.17.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in /home/ubuntu/.pyenv/versions/3.10.5/envs/jupyter3.10.5/lib/python3.10/site-packages (from tensorflow) (2.1.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /home/ubuntu/.pyenv/versions/3.10.5/envs/jupyter3.10.5/lib/python3.10/site-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=24.3.25 in /home/ubuntu/.pyenv/versions/3.10.5/envs/jupyter3.10.5/lib/python3.10/site-packages (from tensorflow) (24.3.25)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /home/ubuntu/.pyenv/versions/3.10.5/envs/jupyter3.10.5/lib/python3.10/site-packages (from tensorflow) (0.6.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /home/ubuntu/.pyenv/versions/3.10.5/envs/jupyter3.10.5/lib/python3.10/site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: h5py>=3.10.0 in /home/ubuntu/.pyenv/versions/3.10.5/envs/jupyter3.10.5/lib/python3.10/site-packages (from tensorflow) (3.11.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in /home/ubuntu/.pyenv/versions/3.10.5/envs/jupyter3.10.5/lib/python3.10/site-packages (from tensorflow) (18.1.1)\n",
      "Requirement already satisfied: ml-dtypes<0.5.0,>=0.3.1 in /home/ubuntu/.pyenv/versions/3.10.5/envs/jupyter3.10.5/lib/python3.10/site-packages (from tensorflow) (0.4.0)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /home/ubuntu/.pyenv/versions/3.10.5/envs/jupyter3.10.5/lib/python3.10/site-packages (from tensorflow) (3.3.0)\n",
      "Requirement already satisfied: packaging in /home/ubuntu/.pyenv/versions/3.10.5/envs/jupyter3.10.5/lib/python3.10/site-packages (from tensorflow) (24.1)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /home/ubuntu/.pyenv/versions/3.10.5/envs/jupyter3.10.5/lib/python3.10/site-packages (from tensorflow) (4.25.4)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /home/ubuntu/.pyenv/versions/3.10.5/envs/jupyter3.10.5/lib/python3.10/site-packages (from tensorflow) (2.32.3)\n",
      "Requirement already satisfied: setuptools in /home/ubuntu/.pyenv/versions/3.10.5/envs/jupyter3.10.5/lib/python3.10/site-packages (from tensorflow) (58.1.0)\n",
      "Requirement already satisfied: six>=1.12.0 in /home/ubuntu/.pyenv/versions/3.10.5/envs/jupyter3.10.5/lib/python3.10/site-packages (from tensorflow) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /home/ubuntu/.pyenv/versions/3.10.5/envs/jupyter3.10.5/lib/python3.10/site-packages (from tensorflow) (2.4.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /home/ubuntu/.pyenv/versions/3.10.5/envs/jupyter3.10.5/lib/python3.10/site-packages (from tensorflow) (4.12.2)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /home/ubuntu/.pyenv/versions/3.10.5/envs/jupyter3.10.5/lib/python3.10/site-packages (from tensorflow) (1.16.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /home/ubuntu/.pyenv/versions/3.10.5/envs/jupyter3.10.5/lib/python3.10/site-packages (from tensorflow) (1.65.4)\n",
      "Requirement already satisfied: tensorboard<2.18,>=2.17 in /home/ubuntu/.pyenv/versions/3.10.5/envs/jupyter3.10.5/lib/python3.10/site-packages (from tensorflow) (2.17.0)\n",
      "Requirement already satisfied: keras>=3.2.0 in /home/ubuntu/.pyenv/versions/3.10.5/envs/jupyter3.10.5/lib/python3.10/site-packages (from tensorflow) (3.4.1)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /home/ubuntu/.pyenv/versions/3.10.5/envs/jupyter3.10.5/lib/python3.10/site-packages (from tensorflow) (0.37.1)\n",
      "Requirement already satisfied: numpy<2.0.0,>=1.23.5 in /home/ubuntu/.pyenv/versions/3.10.5/envs/jupyter3.10.5/lib/python3.10/site-packages (from tensorflow) (1.26.4)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /home/ubuntu/.pyenv/versions/3.10.5/envs/jupyter3.10.5/lib/python3.10/site-packages (from astunparse>=1.6.0->tensorflow) (0.44.0)\n",
      "Requirement already satisfied: rich in /home/ubuntu/.pyenv/versions/3.10.5/envs/jupyter3.10.5/lib/python3.10/site-packages (from keras>=3.2.0->tensorflow) (13.7.1)\n",
      "Requirement already satisfied: namex in /home/ubuntu/.pyenv/versions/3.10.5/envs/jupyter3.10.5/lib/python3.10/site-packages (from keras>=3.2.0->tensorflow) (0.0.8)\n",
      "Requirement already satisfied: optree in /home/ubuntu/.pyenv/versions/3.10.5/envs/jupyter3.10.5/lib/python3.10/site-packages (from keras>=3.2.0->tensorflow) (0.12.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/ubuntu/.pyenv/versions/3.10.5/envs/jupyter3.10.5/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorflow) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/ubuntu/.pyenv/versions/3.10.5/envs/jupyter3.10.5/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorflow) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/ubuntu/.pyenv/versions/3.10.5/envs/jupyter3.10.5/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorflow) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/ubuntu/.pyenv/versions/3.10.5/envs/jupyter3.10.5/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorflow) (2024.7.4)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /home/ubuntu/.pyenv/versions/3.10.5/envs/jupyter3.10.5/lib/python3.10/site-packages (from tensorboard<2.18,>=2.17->tensorflow) (3.6)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /home/ubuntu/.pyenv/versions/3.10.5/envs/jupyter3.10.5/lib/python3.10/site-packages (from tensorboard<2.18,>=2.17->tensorflow) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /home/ubuntu/.pyenv/versions/3.10.5/envs/jupyter3.10.5/lib/python3.10/site-packages (from tensorboard<2.18,>=2.17->tensorflow) (3.0.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /home/ubuntu/.pyenv/versions/3.10.5/envs/jupyter3.10.5/lib/python3.10/site-packages (from werkzeug>=1.0.1->tensorboard<2.18,>=2.17->tensorflow) (2.1.5)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /home/ubuntu/.pyenv/versions/3.10.5/envs/jupyter3.10.5/lib/python3.10/site-packages (from rich->keras>=3.2.0->tensorflow) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /home/ubuntu/.pyenv/versions/3.10.5/envs/jupyter3.10.5/lib/python3.10/site-packages (from rich->keras>=3.2.0->tensorflow) (2.18.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in /home/ubuntu/.pyenv/versions/3.10.5/envs/jupyter3.10.5/lib/python3.10/site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.2.0->tensorflow) (0.1.2)\n"
=======
      "Collecting tensorflow\n",
      "  Downloading tensorflow-2.16.2-cp39-cp39-macosx_10_15_x86_64.whl.metadata (4.1 kB)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in /Users/raviravindran/Documents/Code/ML/python-local-3.9/lib/python3.9/site-packages (from tensorflow) (2.1.0)\n",
      "Collecting astunparse>=1.6.0 (from tensorflow)\n",
      "  Downloading astunparse-1.6.3-py2.py3-none-any.whl.metadata (4.4 kB)\n",
      "Collecting flatbuffers>=23.5.26 (from tensorflow)\n",
      "  Downloading flatbuffers-24.3.25-py2.py3-none-any.whl.metadata (850 bytes)\n",
      "Collecting gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 (from tensorflow)\n",
      "  Downloading gast-0.6.0-py3-none-any.whl.metadata (1.3 kB)\n",
      "Collecting google-pasta>=0.1.1 (from tensorflow)\n",
      "  Downloading google_pasta-0.2.0-py3-none-any.whl.metadata (814 bytes)\n",
      "Requirement already satisfied: h5py>=3.10.0 in /Users/raviravindran/Documents/Code/ML/python-local-3.9/lib/python3.9/site-packages (from tensorflow) (3.11.0)\n",
      "Collecting libclang>=13.0.0 (from tensorflow)\n",
      "  Downloading libclang-18.1.1-py2.py3-none-macosx_10_9_x86_64.whl.metadata (5.2 kB)\n",
      "Collecting ml-dtypes~=0.3.1 (from tensorflow)\n",
      "  Downloading ml_dtypes-0.3.2-cp39-cp39-macosx_10_9_universal2.whl.metadata (20 kB)\n",
      "Collecting opt-einsum>=2.3.2 (from tensorflow)\n",
      "  Downloading opt_einsum-3.3.0-py3-none-any.whl.metadata (6.5 kB)\n",
      "Requirement already satisfied: packaging in /Users/raviravindran/Documents/Code/ML/python-local-3.9/lib/python3.9/site-packages (from tensorflow) (24.1)\n",
      "Collecting protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 (from tensorflow)\n",
      "  Downloading protobuf-4.25.4-cp37-abi3-macosx_10_9_universal2.whl.metadata (541 bytes)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /Users/raviravindran/Documents/Code/ML/python-local-3.9/lib/python3.9/site-packages (from tensorflow) (2.32.3)\n",
      "Requirement already satisfied: setuptools in /Users/raviravindran/Documents/Code/ML/python-local-3.9/lib/python3.9/site-packages (from tensorflow) (69.2.0)\n",
      "Requirement already satisfied: six>=1.12.0 in /Users/raviravindran/Documents/Code/ML/python-local-3.9/lib/python3.9/site-packages (from tensorflow) (1.16.0)\n",
      "Collecting termcolor>=1.1.0 (from tensorflow)\n",
      "  Downloading termcolor-2.4.0-py3-none-any.whl.metadata (6.1 kB)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /Users/raviravindran/Documents/Code/ML/python-local-3.9/lib/python3.9/site-packages (from tensorflow) (4.12.2)\n",
      "Collecting wrapt>=1.11.0 (from tensorflow)\n",
      "  Downloading wrapt-1.16.0-cp39-cp39-macosx_10_9_x86_64.whl.metadata (6.6 kB)\n",
      "Collecting grpcio<2.0,>=1.24.3 (from tensorflow)\n",
      "  Downloading grpcio-1.65.4-cp39-cp39-macosx_10_9_universal2.whl.metadata (3.3 kB)\n",
      "Collecting tensorboard<2.17,>=2.16 (from tensorflow)\n",
      "  Downloading tensorboard-2.16.2-py3-none-any.whl.metadata (1.6 kB)\n",
      "Requirement already satisfied: keras>=3.0.0 in /Users/raviravindran/Documents/Code/ML/python-local-3.9/lib/python3.9/site-packages (from tensorflow) (3.4.1)\n",
      "Collecting tensorflow-io-gcs-filesystem>=0.23.1 (from tensorflow)\n",
      "  Downloading tensorflow_io_gcs_filesystem-0.37.1-cp39-cp39-macosx_10_14_x86_64.whl.metadata (14 kB)\n",
      "Requirement already satisfied: numpy<2.0.0,>=1.23.5 in /Users/raviravindran/Documents/Code/ML/python-local-3.9/lib/python3.9/site-packages (from tensorflow) (1.26.4)\n",
      "Collecting wheel<1.0,>=0.23.0 (from astunparse>=1.6.0->tensorflow)\n",
      "  Downloading wheel-0.44.0-py3-none-any.whl.metadata (2.3 kB)\n",
      "Requirement already satisfied: rich in /Users/raviravindran/Documents/Code/ML/python-local-3.9/lib/python3.9/site-packages (from keras>=3.0.0->tensorflow) (13.7.1)\n",
      "Requirement already satisfied: namex in /Users/raviravindran/Documents/Code/ML/python-local-3.9/lib/python3.9/site-packages (from keras>=3.0.0->tensorflow) (0.0.8)\n",
      "Requirement already satisfied: optree in /Users/raviravindran/Documents/Code/ML/python-local-3.9/lib/python3.9/site-packages (from keras>=3.0.0->tensorflow) (0.12.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/raviravindran/Documents/Code/ML/python-local-3.9/lib/python3.9/site-packages (from requests<3,>=2.21.0->tensorflow) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/raviravindran/Documents/Code/ML/python-local-3.9/lib/python3.9/site-packages (from requests<3,>=2.21.0->tensorflow) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/raviravindran/Documents/Code/ML/python-local-3.9/lib/python3.9/site-packages (from requests<3,>=2.21.0->tensorflow) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/raviravindran/Documents/Code/ML/python-local-3.9/lib/python3.9/site-packages (from requests<3,>=2.21.0->tensorflow) (2024.7.4)\n",
      "Collecting markdown>=2.6.8 (from tensorboard<2.17,>=2.16->tensorflow)\n",
      "  Downloading Markdown-3.6-py3-none-any.whl.metadata (7.0 kB)\n",
      "Collecting tensorboard-data-server<0.8.0,>=0.7.0 (from tensorboard<2.17,>=2.16->tensorflow)\n",
      "  Downloading tensorboard_data_server-0.7.2-py3-none-macosx_10_9_x86_64.whl.metadata (1.1 kB)\n",
      "Collecting werkzeug>=1.0.1 (from tensorboard<2.17,>=2.16->tensorflow)\n",
      "  Downloading werkzeug-3.0.3-py3-none-any.whl.metadata (3.7 kB)\n",
      "Requirement already satisfied: importlib-metadata>=4.4 in /Users/raviravindran/Documents/Code/ML/python-local-3.9/lib/python3.9/site-packages (from markdown>=2.6.8->tensorboard<2.17,>=2.16->tensorflow) (8.2.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /Users/raviravindran/Documents/Code/ML/python-local-3.9/lib/python3.9/site-packages (from werkzeug>=1.0.1->tensorboard<2.17,>=2.16->tensorflow) (2.1.5)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /Users/raviravindran/Documents/Code/ML/python-local-3.9/lib/python3.9/site-packages (from rich->keras>=3.0.0->tensorflow) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /Users/raviravindran/Documents/Code/ML/python-local-3.9/lib/python3.9/site-packages (from rich->keras>=3.0.0->tensorflow) (2.18.0)\n",
      "Requirement already satisfied: zipp>=0.5 in /Users/raviravindran/Documents/Code/ML/python-local-3.9/lib/python3.9/site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.17,>=2.16->tensorflow) (3.20.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in /Users/raviravindran/Documents/Code/ML/python-local-3.9/lib/python3.9/site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.0.0->tensorflow) (0.1.2)\n",
      "Downloading tensorflow-2.16.2-cp39-cp39-macosx_10_15_x86_64.whl (259.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m259.5/259.5 MB\u001b[0m \u001b[31m15.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
      "Downloading flatbuffers-24.3.25-py2.py3-none-any.whl (26 kB)\n",
      "Downloading gast-0.6.0-py3-none-any.whl (21 kB)\n",
      "Downloading google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
      "Downloading grpcio-1.65.4-cp39-cp39-macosx_10_9_universal2.whl (10.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.5/10.5 MB\u001b[0m \u001b[31m15.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading libclang-18.1.1-py2.py3-none-macosx_10_9_x86_64.whl (26.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m26.5/26.5 MB\u001b[0m \u001b[31m15.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading ml_dtypes-0.3.2-cp39-cp39-macosx_10_9_universal2.whl (389 kB)\n",
      "Downloading opt_einsum-3.3.0-py3-none-any.whl (65 kB)\n",
      "Downloading protobuf-4.25.4-cp37-abi3-macosx_10_9_universal2.whl (394 kB)\n",
      "Downloading tensorboard-2.16.2-py3-none-any.whl (5.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.5/5.5 MB\u001b[0m \u001b[31m18.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading tensorflow_io_gcs_filesystem-0.37.1-cp39-cp39-macosx_10_14_x86_64.whl (2.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m17.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading termcolor-2.4.0-py3-none-any.whl (7.7 kB)\n",
      "Downloading wrapt-1.16.0-cp39-cp39-macosx_10_9_x86_64.whl (37 kB)\n",
      "Downloading Markdown-3.6-py3-none-any.whl (105 kB)\n",
      "Downloading tensorboard_data_server-0.7.2-py3-none-macosx_10_9_x86_64.whl (4.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.8/4.8 MB\u001b[0m \u001b[31m15.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading werkzeug-3.0.3-py3-none-any.whl (227 kB)\n",
      "Downloading wheel-0.44.0-py3-none-any.whl (67 kB)\n",
      "Installing collected packages: libclang, flatbuffers, wrapt, wheel, werkzeug, termcolor, tensorflow-io-gcs-filesystem, tensorboard-data-server, protobuf, opt-einsum, ml-dtypes, grpcio, google-pasta, gast, markdown, astunparse, tensorboard, tensorflow\n",
      "  Attempting uninstall: ml-dtypes\n",
      "    Found existing installation: ml-dtypes 0.4.0\n",
      "    Uninstalling ml-dtypes-0.4.0:\n",
      "      Successfully uninstalled ml-dtypes-0.4.0\n",
      "Successfully installed astunparse-1.6.3 flatbuffers-24.3.25 gast-0.6.0 google-pasta-0.2.0 grpcio-1.65.4 libclang-18.1.1 markdown-3.6 ml-dtypes-0.3.2 opt-einsum-3.3.0 protobuf-4.25.4 tensorboard-2.16.2 tensorboard-data-server-0.7.2 tensorflow-2.16.2 tensorflow-io-gcs-filesystem-0.37.1 termcolor-2.4.0 werkzeug-3.0.3 wheel-0.44.0 wrapt-1.16.0\n"
>>>>>>> c0d76dea41e18673eacb464f1d9edb6204629218
     ]
    }
   ],
   "source": [
    "!pip install -q -U keras-nlp\n",
    "!pip install -q -U \"keras>=3\"\n",
<<<<<<< HEAD
    "!pip install tensorflow"
=======
    "!pip install tensorflow\n"
>>>>>>> c0d76dea41e18673eacb464f1d9edb6204629218
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"KERAS_BACKEND\"] = \"jax\"  # Or \"tensorflow\" or \"torch\".\n",
    "os.environ[\"XLA_PYTHON_CLIENT_MEM_FRACTION\"] = \"0.9\""
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 4,
=======
   "execution_count": 17,
>>>>>>> c0d76dea41e18673eacb464f1d9edb6204629218
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "import keras_nlp\n",
<<<<<<< HEAD
    "import os\n",
    "#from tensorflow.keras.utils import get_file\n",
    "\n",
    "# This is a dummy call to see where files might be downloaded\n",
    "# You don't need to run this with a real URL, it's just for demonstration\n",
    "#path = get_file('dummy_model', origin='https://example.com/dummy_model.h5', cache_subdir='models')\n",
    "#print(os.path.dirname(path))"
=======
    "import numpy as np\n"
>>>>>>> c0d76dea41e18673eacb464f1d9edb6204629218
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export KAGGLE_USERNAME=raviravindran\n",
    "#export KAGGLE_KEY=31715b36fb6c26b555ad2640b1a59f5c\n",
    "#pip install -q -U  tensorflow-text\n",
    "import tensorflow_text as tf_text\n",
    "gemma_lm = keras_nlp.models.GemmaCausalLM.from_preset(\"gemma2_instruct_2b_en\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
=======
   "execution_count": 22,
>>>>>>> c0d76dea41e18673eacb464f1d9edb6204629218
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
<<<<<<< HEAD
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1723487754.786218   19875 service.cc:146] XLA service 0x7faec6d514a0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1723487754.786408   19875 service.cc:154]   StreamExecutor device (0): Host, Default Version\n",
      "I0000 00:00:1723487757.506515   19875 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['Keras is a high-level deep learning API that runs on top of TensorFlow, Theano, or CNTK. It provides a user-',\n",
       " 'I want to say thank you to the people who helped me through the tough times.\\n\\nI want to express my gratitude to those who stood by']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
=======
      "Python(86176) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "Python(86177) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "<class 'keras_nlp.src.models.gemma.gemma_tokenizer.GemmaTokenizer'> could not be deserialized properly. Please ensure that components that are Python object instances (layers, models, etc.) returned by `get_config()` are explicitly deserialized in the model's `from_config()` method.\n\nconfig={'module': 'keras_nlp.src.models.gemma.gemma_tokenizer', 'class_name': 'GemmaTokenizer', 'config': {'name': 'gemma_tokenizer', 'trainable': True, 'dtype': 'int32', 'proto': None, 'sequence_length': None}, 'registered_name': 'keras_nlp>GemmaTokenizer'}.\n\nException encountered: Error when deserializing class 'GemmaTokenizer' using config={'name': 'gemma_tokenizer', 'trainable': True, 'dtype': 'int32', 'proto': None, 'sequence_length': None}.\n\nException encountered: GemmaTokenizer requires the `tensorflow-text` package. Please install with `pip install tensorflow-text`.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "File \u001b[0;32m~/Documents/Code/ML/python-local-3.9/lib/python3.9/site-packages/keras/src/ops/operation.py:234\u001b[0m, in \u001b[0;36mOperation.from_config\u001b[0;34m(cls, config)\u001b[0m\n\u001b[1;32m    233\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 234\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    235\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/Documents/Code/ML/python-local-3.9/lib/python3.9/site-packages/keras_nlp/src/models/gemma/gemma_tokenizer.py:85\u001b[0m, in \u001b[0;36mGemmaTokenizer.__init__\u001b[0;34m(self, proto, **kwargs)\u001b[0m\n\u001b[1;32m     83\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpad_token \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m<pad>\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m---> 85\u001b[0m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mproto\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mproto\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/Code/ML/python-local-3.9/lib/python3.9/site-packages/keras_nlp/src/tokenizers/sentence_piece_tokenizer.py:121\u001b[0m, in \u001b[0;36mSentencePieceTokenizer.__init__\u001b[0;34m(self, proto, sequence_length, dtype, **kwargs)\u001b[0m\n\u001b[1;32m    114\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\n\u001b[1;32m    115\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    116\u001b[0m     proto\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    119\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m    120\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 121\u001b[0m     \u001b[43massert_tf_text_installed\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;18;43m__class__\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;18;43m__name__\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    123\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_int_dtype(dtype) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_string_dtype(dtype):\n",
      "File \u001b[0;32m~/Documents/Code/ML/python-local-3.9/lib/python3.9/site-packages/keras_nlp/src/utils/tensor_utils.py:144\u001b[0m, in \u001b[0;36massert_tf_text_installed\u001b[0;34m(symbol_name)\u001b[0m\n\u001b[1;32m    143\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m tf_text \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 144\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(\n\u001b[1;32m    145\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00msymbol_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m requires the `tensorflow-text` package. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    146\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPlease install with `pip install tensorflow-text`.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    147\u001b[0m     )\n",
      "\u001b[0;31mImportError\u001b[0m: GemmaTokenizer requires the `tensorflow-text` package. Please install with `pip install tensorflow-text`.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[0;32m~/Documents/Code/ML/python-local-3.9/lib/python3.9/site-packages/keras/src/saving/serialization_lib.py:718\u001b[0m, in \u001b[0;36mdeserialize_keras_object\u001b[0;34m(config, custom_objects, safe_mode, **kwargs)\u001b[0m\n\u001b[1;32m    717\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 718\u001b[0m     instance \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_config\u001b[49m\u001b[43m(\u001b[49m\u001b[43minner_config\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    719\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/Documents/Code/ML/python-local-3.9/lib/python3.9/site-packages/keras/src/ops/operation.py:236\u001b[0m, in \u001b[0;36mOperation.from_config\u001b[0;34m(cls, config)\u001b[0m\n\u001b[1;32m    235\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m--> 236\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[1;32m    237\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mError when deserializing class \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m using \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    238\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mconfig=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconfig\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mException encountered: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    239\u001b[0m     )\n",
      "\u001b[0;31mTypeError\u001b[0m: Error when deserializing class 'GemmaTokenizer' using config={'name': 'gemma_tokenizer', 'trainable': True, 'dtype': 'int32', 'proto': None, 'sequence_length': None}.\n\nException encountered: GemmaTokenizer requires the `tensorflow-text` package. Please install with `pip install tensorflow-text`.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[22], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m get_ipython()\u001b[38;5;241m.\u001b[39msystem(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mexport KAGGLE_KEY=31715b36fb6c26b555ad2640b1a59f5c\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m#!pip install -q -U  tensorflow-text\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m gemma_lm \u001b[38;5;241m=\u001b[39m \u001b[43mkeras_nlp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodels\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mGemmaCausalLM\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_preset\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mgemma2_instruct_2b_en\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m start_of_turn_user \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m<start_of_turn>user\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      6\u001b[0m start_of_turn_model \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m<start_of_turn>model\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[0;32m~/Documents/Code/ML/python-local-3.9/lib/python3.9/site-packages/keras_nlp/src/models/task.py:272\u001b[0m, in \u001b[0;36mTask.from_preset\u001b[0;34m(cls, preset, load_weights, **kwargs)\u001b[0m\n\u001b[1;32m    270\u001b[0m     preprocessor \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpreprocessor\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    271\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 272\u001b[0m     preprocessor \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpreprocessor_cls\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_preset\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpreset\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    273\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mcls\u001b[39m(backbone\u001b[38;5;241m=\u001b[39mbackbone, preprocessor\u001b[38;5;241m=\u001b[39mpreprocessor, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/Documents/Code/ML/python-local-3.9/lib/python3.9/site-packages/keras_nlp/src/models/preprocessor.py:190\u001b[0m, in \u001b[0;36mPreprocessor.from_preset\u001b[0;34m(cls, preset, **kwargs)\u001b[0m\n\u001b[1;32m    183\u001b[0m         names \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mx\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m`\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m subclasses)\n\u001b[1;32m    184\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    185\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAmbiguous call to `\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.from_preset()`. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    186\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFound multiple possible subclasses \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnames\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    187\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPlease call `from_preset` on a subclass directly.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    188\u001b[0m         )\n\u001b[0;32m--> 190\u001b[0m tokenizer \u001b[38;5;241m=\u001b[39m \u001b[43mload_serialized_object\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpreset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mTOKENIZER_CONFIG_FILE\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    191\u001b[0m tokenizer\u001b[38;5;241m.\u001b[39mload_preset_assets(preset)\n\u001b[1;32m    192\u001b[0m preprocessor \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mcls\u001b[39m(tokenizer\u001b[38;5;241m=\u001b[39mtokenizer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/Documents/Code/ML/python-local-3.9/lib/python3.9/site-packages/keras_nlp/src/utils/preset_utils.py:569\u001b[0m, in \u001b[0;36mload_serialized_object\u001b[0;34m(preset, config_file, config_overrides)\u001b[0m\n\u001b[1;32m    567\u001b[0m config \u001b[38;5;241m=\u001b[39m load_config(preset, config_file)\n\u001b[1;32m    568\u001b[0m config[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mconfig\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m {\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mconfig[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mconfig\u001b[39m\u001b[38;5;124m\"\u001b[39m], \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mconfig_overrides}\n\u001b[0;32m--> 569\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mkeras\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msaving\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdeserialize_keras_object\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/Code/ML/python-local-3.9/lib/python3.9/site-packages/keras/src/saving/serialization_lib.py:720\u001b[0m, in \u001b[0;36mdeserialize_keras_object\u001b[0;34m(config, custom_objects, safe_mode, **kwargs)\u001b[0m\n\u001b[1;32m    718\u001b[0m     instance \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39mfrom_config(inner_config)\n\u001b[1;32m    719\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m--> 720\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[1;32m    721\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mcls\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m could not be deserialized properly. Please\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    722\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m ensure that components that are Python object\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    723\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m instances (layers, models, etc.) returned by\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    724\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m `get_config()` are explicitly deserialized in the\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    725\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m model\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124ms `from_config()` method.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    726\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mconfig=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconfig\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mException encountered: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    727\u001b[0m     )\n\u001b[1;32m    728\u001b[0m build_config \u001b[38;5;241m=\u001b[39m config\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbuild_config\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m    729\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m build_config \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m instance\u001b[38;5;241m.\u001b[39mbuilt:\n",
      "\u001b[0;31mTypeError\u001b[0m: <class 'keras_nlp.src.models.gemma.gemma_tokenizer.GemmaTokenizer'> could not be deserialized properly. Please ensure that components that are Python object instances (layers, models, etc.) returned by `get_config()` are explicitly deserialized in the model's `from_config()` method.\n\nconfig={'module': 'keras_nlp.src.models.gemma.gemma_tokenizer', 'class_name': 'GemmaTokenizer', 'config': {'name': 'gemma_tokenizer', 'trainable': True, 'dtype': 'int32', 'proto': None, 'sequence_length': None}, 'registered_name': 'keras_nlp>GemmaTokenizer'}.\n\nException encountered: Error when deserializing class 'GemmaTokenizer' using config={'name': 'gemma_tokenizer', 'trainable': True, 'dtype': 'int32', 'proto': None, 'sequence_length': None}.\n\nException encountered: GemmaTokenizer requires the `tensorflow-text` package. Please install with `pip install tensorflow-text`."
     ]
    }
   ],
   "source": [
    "#!export KAGGLE_USERNAME=raviravindran\n",
    "#!export KAGGLE_KEY=31715b36fb6c26b555ad2640b1a59f5c\n",
    "#!pip install -q -U  tensorflow-text\n",
    "import tensorflow_text as tf_text\n",
    "print(tf_text.__version__)\n",
    "gemma_lm = keras_nlp.models.GemmaCausalLM.from_preset(\"gemma2_instruct_2b_en\")\n",
>>>>>>> c0d76dea41e18673eacb464f1d9edb6204629218
    "start_of_turn_user = \"<start_of_turn>user\\n\"\n",
    "start_of_turn_model = \"<start_of_turn>model\\n\"\n",
    "end_of_turn = \"<end_of_turn>\\n\"\n",
    "prompt = start_of_turn_user + \"You are a friendly assistant. Say hi.\" + \\\n",
    "    end_of_turn + start_of_turn_model\n",
    "gemma_lm.generate(prompt, max_length=30)\n",
    "\n",
    "# Generate with batched prompts.\n",
<<<<<<< HEAD
    "gemma_lm.generate([\"Keras is a\", \"I want to say\"], max_length=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"I want to say thank you to all the people who have helped me in my life. \\n\\nI'm so grateful for all the love\""
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gemma_lm = keras_nlp.models.GemmaCausalLM.from_preset(\"gemma2_instruct_2b_en\")\n",
    "gemma_lm.compile(sampler=\"top_k\")\n",
    "gemma_lm.generate(\"I want to say\", max_length=30)\n",
    "\n",
    "gemma_lm.compile(sampler=keras_nlp.samplers.BeamSampler(num_beams=2))\n",
    "gemma_lm.generate(\"I want to say\", max_length=30)"
=======
    "gemma_lm.generate([\"Keras is a\", \"I want to say\"], max_length=30)\n"
>>>>>>> c0d76dea41e18673eacb464f1d9edb6204629218
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
<<<<<<< HEAD
   "display_name": "Python 3",
=======
   "display_name": "python-local-3.9",
>>>>>>> c0d76dea41e18673eacb464f1d9edb6204629218
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
<<<<<<< HEAD
   "version": "3.10.5"
=======
   "version": "3.9.19"
>>>>>>> c0d76dea41e18673eacb464f1d9edb6204629218
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
